# -*- coding: utf-8 -*-
"""modbus_rf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IuXO-10JUGRRD5xzY1dsAZXujhN_YcUk
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

df = pd.read_csv('data/IoT_Modbus.csv')  # no need to clean the data since it's already processed!
df.dropna(inplace=True)

df.drop(columns=['date', 'time', 'type'], inplace=True)  # if time later use type

# df['date'] = df['date'].str.strip()
# df['time'] = df['time'].str.strip()

# print(df['label'].value_counts()[1])
# print(df['label'].value_counts()[0])

# df['time'] = pd.to_datetime(df['date'] + ' ' + df['time'], format='%d-%b-%y %H:%M:%S')

# df['time'] = df['time'].apply(lambda x: x.timestamp())
# df.drop(columns=['date', 'label'], inplace=True)
# #df.set_index('time', inplace=True)

# class_names = df['type'].unique().tolist()

df

y = df['label']
X = df.drop(columns=['label'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest with 100 trees
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Predict on test set
y_pred = clf.predict(X_test)

# Print accuracy and classification report
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt

# Get feature importances from the trained model
importances = clf.feature_importances_
feature_names = X.columns

# Plot feature importance
plt.figure(figsize=(8, 5))
plt.barh(feature_names, importances, color='skyblue')
plt.xlabel("Feature Importance")
plt.ylabel("Feature Name")
plt.title("Feature Importance in Random Forest")
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix using Seaborn for better visualization
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["Normal", "Attack"], yticklabels=["Normal", "Attack"])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

# Assuming 'X' is your existing dataset with the features
# and 'clf' is your trained Random Forest model
def generate():
    # Step 1: Generate 100 synthetic data points
    synthetic_data = pd.DataFrame({
        'FC1_Read_Input_Register': np.random.randint(low=X['FC1_Read_Input_Register'].min(),
                                                    high=X['FC1_Read_Input_Register'].max(), size=100),
        'FC2_Read_Discrete_Value': np.random.randint(low=X['FC2_Read_Discrete_Value'].min(),
                                                    high=X['FC2_Read_Discrete_Value'].max(), size=100),
        'FC3_Read_Holding_Register': np.random.randint(low=X['FC3_Read_Holding_Register'].min(),
                                                    high=X['FC3_Read_Holding_Register'].max(), size=100),
        'FC4_Read_Coil': np.random.randint(low=X['FC4_Read_Coil'].min(),
                                        high=X['FC4_Read_Coil'].max(), size=100)
    })

    # Assuming 'df' is your original dataset with a 'label' column where 1 = attack
    attack_rows = df[df['label'] == 1]  # Get rows where the label is 1 (attack)

    # Randomly sample a subset of attack rows (e.g., 20 samples)
    attack_samples = attack_rows.sample(n=20, random_state=42)  # Sample 20 attack rows


    # Step 2: Replace some rows in the synthetic data with attack rows
    attack_indices = np.random.choice(synthetic_data.index, size=20, replace=False)  # Choose 20 rows to replace

    # Replace the selected rows with the attack data
    synthetic_data.loc[attack_indices] = attack_samples[['FC1_Read_Input_Register', 'FC2_Read_Discrete_Value',
                                                        'FC3_Read_Holding_Register', 'FC4_Read_Coil']].values

    # Add the attack label for these rows
    synthetic_data.loc[attack_indices, 'label'] = 1  # Mark these rows as attacks

    for i in range(len(synthetic_data)):  # this shit so ass
        if pd.isna(synthetic_data.loc[i, 'label']):
            synthetic_data.loc[i, 'label'] = 0

    print(synthetic_data)
    (synthetic_data['label'] == 1).sum()
    return synthetic_data